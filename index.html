>>>>>>> Comments feature fully implemented
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400..800;1,400..800&family=IBM+Plex+Sans+Condensed:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&family=Lora:ital,wght@0,400..700;1,400..700&display=swap" rel="stylesheet">
    <title>Jonathan Cola&ccedil;o Carr</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
<div id="page-container">
    <div id="content-wrap">
    <h1>Jonathan Cola&ccedil;o Carr</h1>
    <div id="email-wrapper">
        <p>Email: <a href="mailto:jonathan.colacocarr@mail.mcgill.ca" class="noFrills">jonathan.colacocarr@mail.mcgill.ca</a>
    </div>
    <div id="body-wrapper">
        <!--
        <div id="greetings">
            <h3>Bonjour/Hi!</h3>
        </div>
        -->
        <div id="bio" class="lora-light">
            <p>I am finishing a master’s degree in computer science at McGill University and
            <a href="https://mila.quebec/en" class="noFrills">Mila</a>, where I do research on decision-making algorithms that act both under uncertainty and towards a greater social good. For this, I use methods from computational social choice, game theory, and reinforcement learning.
            </p>

            <p>
                During the 2024&#8211;2025 academic year I was a visiting student researcher at Stanford, and prior to that I was a research intern at UC Berkeley's <a href="https://humancompatible.ai/" class="noFrills">Center for Human-Compatible AI</a>. My master’s research was supported by the NSERC Canada Graduate Scholarship and a Mitacs GlobaLink research award.
            </p>

            <!--
            <p>My recent projects have asked a few simple questions:<br>
            <ul>
            <li><i>Which preference models can AI systems satisfy?</i> Many sequential decision-making algorithms assume that our goals can be captured by a single statistic (sometimes called ``reward'').
                This is often not the case, and I've explored two alternative algorithms that can handle different kinds feedback.
            </li>
            <br>
            <li><i>What is the "Helpful and Harmless" tradeoff? What resolves it?</i> After a thorough audit of this alledged trade-off in language models, this seemed less of a fundamental problem and more of a methodology problem.
                I believe that adding structure to the data will help. I've shown that this works for agents in sequential decision-making tasks.
            </li>
            </ul>
            </p>
            -->
            <p>
                Outside of academia, I lead a small team of software developers at <a href="https://hortus.ai/" class="noFrills">Hortus AI</a>.
                We’re creating a marketplace for public-sector AI that's designed to make partnerships transparent, ethical, and easy to navigate.
            </p>

            <p>
                I am looking for PhD opportunities! Here is my <a href="J_Colaco_Carr_resume_Oct2025.pdf">resume</a>.
            </p>
        </div>
    <!--
    <div id="links" class="ibm-plex-sans-condensed-light">
        <p><span style="font-size:1.17em">You can find my work on</span><br>
            <a href="https://scholar.google.com/citations?user=IRKWTTwAAAAJ&hl=en">Google Scholar</a>,
            <a href="https://github.com/j-c-carr/">GitHub</a> or
            <a href="https://www.linkedin.com/in/jonathan-colaco-carr/">Linkedin</a>.
    </div>
    -->
    </div>
    </div>
</div>
</body>
</html>
